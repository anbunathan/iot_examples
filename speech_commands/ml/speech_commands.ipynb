{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech_commands.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrOnc95wvhhc"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZguagqSEuh7"
      },
      "source": [
        "# after installing re-start environment for pandas-ml to work properly\r\n",
        "! pip install backcall==0.1.0\r\n",
        "! pip install colorama==0.4.3\r\n",
        "! pip install cycler==0.10.0\r\n",
        "! pip install decorator==4.4.2\r\n",
        "! pip install enum34==1.1.10\r\n",
        "! pip install imbalanced-learn==0.4.3\r\n",
        "! pip install ipykernel==5.2.1\r\n",
        "! pip install ipython==7.14.0\r\n",
        "! pip install ipython-genutils==0.2.0\r\n",
        "! pip install jedi==0.17.0\r\n",
        "! pip install joblib==0.15.0\r\n",
        "! pip install jupyter-client==6.1.3\r\n",
        "! pip install jupyter-core==4.6.3\r\n",
        "! pip install kiwisolver==1.2.0\r\n",
        "! pip install matplotlib==3.2.1\r\n",
        "! pip install numpy==1.15.4\r\n",
        "! pip install pandas==0.24.2\r\n",
        "! pip install pandas-ml==0.6.1\r\n",
        "! pip install parso==0.7.0\r\n",
        "! pip install pickleshare==0.7.5\r\n",
        "! pip install prompt-toolkit==3.0.5\r\n",
        "! pip install Pygments==2.6.1\r\n",
        "! pip install pyparsing==2.4.7\r\n",
        "! pip install python-dateutil==2.8.1\r\n",
        "! pip install pytz==2020.1\r\n",
        "! pip install pywin32==227\r\n",
        "! pip install pyzmq==19.0.1\r\n",
        "! pip install scikit-learn==0.20.0\r\n",
        "! pip install scipy==1.3.3\r\n",
        "! pip install six==1.14.0\r\n",
        "! pip install threadpoolctl==2.0.0\r\n",
        "! pip install tornado==6.0.4\r\n",
        "! pip install traitlets==4.3.3\r\n",
        "! pip install wcwidth==0.1.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMxdyA9uxLD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c296b52f-3082-4230-941b-dd5f99badf54"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBhqp0GwwcMS"
      },
      "source": [
        "import os\n",
        "import wget\n",
        "import tarfile"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Yx_17Tweli"
      },
      "source": [
        "from shutil import rmtree"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cecoFI2zwgg7"
      },
      "source": [
        "DATASET_URL = 'http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz'\n",
        "ARCHIVE = os.path.basename(DATASET_URL)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUqYsJWuwmHY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77619f03-0c29-484d-c06c-94606f269281"
      },
      "source": [
        "wget.download(DATASET_URL)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'speech_commands_v0.01.tar.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FT2VH_qEe8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "215f42d5-d3d9-4c01-c6a7-f3fe75c8dff6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'speech/'\n",
        "import sys\n",
        "sys.path.append(base_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt98m8hMEZL9"
      },
      "source": [
        "from pathlib import Path\n",
        "current_dir = Path.cwd()\n",
        "data_dir = Path(current_dir,'data')\n",
        "train_dir = Path(data_dir, 'train')\n",
        "if os.path.exists(train_dir):\n",
        "  rmtree(train_dir)\n",
        "os.makedirs(train_dir)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54Cw8-8pwrsF"
      },
      "source": [
        "with tarfile.open(ARCHIVE, 'r:gz') as tar:\n",
        "  # tar.extractall(path='data/train')\n",
        "  tar.extractall(path=train_dir)\n",
        "\n",
        "os.remove(ARCHIVE)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATk4Ruk1Q8xK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff5d2da-00b4-41e0-971c-3a498f864025"
      },
      "source": [
        "from pathlib import Path\n",
        "current_dir = Path.cwd()\n",
        "data_dir = Path(current_dir,'data')\n",
        "train_dir = Path(data_dir, 'train')\n",
        "checkpt_dir = Path(current_dir,'checkpoint')\n",
        "print(\"train_dir = \",train_dir)\n",
        "print(\"checkpt_dir = \",checkpt_dir)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_dir =  /content/data/train\n",
            "checkpt_dir =  /content/checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kREgOmy-PCAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fc4527-53d6-4617-de82-872025a3de4b"
      },
      "source": [
        "!pip install keras-applications==1.0.7\n",
        "!pip install keras_preprocessing==1.0.1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-applications==1.0.7 in /usr/local/lib/python3.6/dist-packages (1.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications==1.0.7) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications==1.0.7) (1.15.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications==1.0.7) (1.14.0)\n",
            "Collecting keras_preprocessing==1.0.1\n",
            "  Using cached https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing==1.0.1) (1.14.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing==1.0.1) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing==1.0.1) (1.15.4)\n",
            "Requirement already satisfied: keras>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing==1.0.1) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras_preprocessing==1.0.1) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras_preprocessing==1.0.1) (2.10.0)\n",
            "\u001b[31mERROR: tensorflow 2.4.0 has requirement keras-preprocessing~=1.1.2, but you'll have keras-preprocessing 1.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.0 has requirement numpy~=1.19.2, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.0 has requirement six~=1.15.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-preprocessing\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "Successfully installed keras-preprocessing-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L66K_IbURbBb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db58b6fd-c787-46cc-b345-60315aa6478e"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Collecting six~=1.15.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting numpy~=1.19.2\n",
            "  Using cached https://files.pythonhosted.org/packages/14/32/d3fa649ad7ec0b82737b92fefd3c4dd376b0bb23730715124569f38f3a08/numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (51.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 6.1.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, numpy, keras-preprocessing\n",
            "  Found existing installation: six 1.14.0\n",
            "    Uninstalling six-1.14.0:\n",
            "      Successfully uninstalled six-1.14.0\n",
            "  Found existing installation: numpy 1.15.4\n",
            "    Uninstalling numpy-1.15.4:\n",
            "      Successfully uninstalled numpy-1.15.4\n",
            "  Found existing installation: Keras-Preprocessing 1.0.1\n",
            "    Uninstalling Keras-Preprocessing-1.0.1:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.1\n",
            "Successfully installed keras-preprocessing-1.1.2 numpy-1.19.5 six-1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTfbZiKWUPSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e7a6ac4-63ef-4a3b-d396-c4e54d7b26bc"
      },
      "source": [
        "!pip install git+https://github.com/hyperopt/hyperopt-sklearn.git"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
            "  Cloning https://github.com/hyperopt/hyperopt-sklearn.git to /tmp/pip-req-build-dmh9qgsb\n",
            "  Running command git clone -q https://github.com/hyperopt/hyperopt-sklearn.git /tmp/pip-req-build-dmh9qgsb\n",
            "Requirement already satisfied (use --upgrade to upgrade): hpsklearn==0.0.3 from git+https://github.com/hyperopt/hyperopt-sklearn.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (0.1.2)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (0.20.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (4.41.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (2.5)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (3.11.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hpsklearn==0.0.3) (4.4.2)\n",
            "Building wheels for collected packages: hpsklearn\n",
            "  Building wheel for hpsklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpsklearn: filename=hpsklearn-0.0.3-cp36-none-any.whl size=26923 sha256=8d3f78a2d41b46c772ed236fc04d97eed50be179a1eb093230654c1648aea57d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_i_8jnf1/wheels/28/93/20/67dca95c2aaa13466b4900ba79a7bab66022e50ce44f8a438d\n",
            "Successfully built hpsklearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a76jDvt9u0v"
      },
      "source": [
        "import model\n",
        "import generator\n",
        "import classes\n",
        "import utils"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LsR_D70_9Tt"
      },
      "source": [
        "from pandas_ml import ConfusionMatrix"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0g4YdWMx6h4"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.callbacks import TensorBoard\n",
        "from callbacks import ConfusionMatrixCallback\n",
        "from model import speech_model, prepare_model_settings\n",
        "from generator import AudioProcessor, prepare_words_list\n",
        "from classes import get_classes\n",
        "from utils import data_gen"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9BFBlIwrg29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca14c4f6-a680-450b-b7a5-e6683a956eae"
      },
      "source": [
        "# args = parser.parse_args()\n",
        "args = {}\n",
        "args['data_dirs'] = train_dir\n",
        "args['sample_rate'] = 16000\n",
        "args['batch_size'] = 64\n",
        "args['output_representation'] = 'raw'\n",
        "# parser.print_help()\n",
        "print('input args: ', args)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input args:  {'data_dirs': PosixPath('/content/data/train'), 'sample_rate': 16000, 'batch_size': 64, 'output_representation': 'raw'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riwyHrUu6u-U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "outputId": "2357202b-01a6-4efe-cf92-d5903d5aba85"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/aa/ae64be5acaac9055329289e6bfd54c1efa28bfe792f9021cea495fe2b89d/tensorflow_gpu-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (51.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWWQ23G2-m9B"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.compat.v1.keras import backend as K\n",
        "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.0)\n",
        "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "K.set_session(sess)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQHaFkEH56z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9251b85-f19c-474a-f8f1-7ce220ed3c79"
      },
      "source": [
        "\n",
        "p = args['data_dirs']\n",
        "print(\"p = \", p)\n",
        "data_dirs = [str(x) for x in p.iterdir() if x.is_dir()]\n",
        "# data_dirs=(args['data_dirs'])\n",
        "print(\"data_dirs = \", data_dirs)\n",
        "output_representation = args['output_representation']\n",
        "sample_rate = args['sample_rate']\n",
        "batch_size = args['batch_size']\n",
        "classes = get_classes(wanted_only=True)\n",
        "print(\"classes = \", classes)\n",
        "model_settings = prepare_model_settings(\n",
        "    label_count=len(prepare_words_list(classes)),\n",
        "    sample_rate=sample_rate,\n",
        "    clip_duration_ms=1000,\n",
        "    window_size_ms=30.0,\n",
        "    window_stride_ms=10.0,\n",
        "    dct_coefficient_count=80,\n",
        "    num_log_mel_features=60,\n",
        "    output_representation=output_representation)\n",
        "\n",
        "print(model_settings)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p =  /content/data/train\n",
            "data_dirs =  ['/content/data/train/dog', '/content/data/train/yes', '/content/data/train/happy', '/content/data/train/bed', '/content/data/train/up', '/content/data/train/marvin', '/content/data/train/bird', '/content/data/train/three', '/content/data/train/eight', '/content/data/train/four', '/content/data/train/sheila', '/content/data/train/two', '/content/data/train/no', '/content/data/train/_background_noise_', '/content/data/train/cat', '/content/data/train/right', '/content/data/train/stop', '/content/data/train/zero', '/content/data/train/five', '/content/data/train/tree', '/content/data/train/seven', '/content/data/train/off', '/content/data/train/left', '/content/data/train/down', '/content/data/train/one', '/content/data/train/go', '/content/data/train/on', '/content/data/train/nine', '/content/data/train/house', '/content/data/train/wow', '/content/data/train/six']\n",
            "classes =  ['stop', 'down', 'off', 'right', 'up', 'go', 'on', 'yes', 'left', 'no']\n",
            "{'desired_samples': 16000, 'window_size_samples': 480, 'window_stride_samples': 160, 'spectrogram_length': 98, 'spectrogram_frequencies': 257, 'dct_coefficient_count': 80, 'fingerprint_size': 16000, 'label_count': 12, 'sample_rate': 16000, 'num_log_mel_features': 60}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8vsMUb1_lm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d5debc-c687-4e1e-d4c0-2493c5883a60"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "ap = AudioProcessor(\n",
        "    data_dirs=data_dirs,\n",
        "    wanted_words=classes,\n",
        "    silence_percentage=13.0,\n",
        "    unknown_percentage=60.0,\n",
        "    validation_percentage=10.0,\n",
        "    testing_percentage=0.0,\n",
        "    model_settings=model_settings,\n",
        "    output_representation=output_representation)\n",
        "train_gen = data_gen(ap, sess, batch_size=batch_size, mode='training')\n",
        "val_gen = data_gen(ap, sess, batch_size=batch_size, mode='validation')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "shape of self.spectrogram_ =  Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
            "prepare_processing_graph completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONXA3qS53U80"
      },
      "source": [
        "model = speech_model(\n",
        "    'conv_1d_time_stacked',\n",
        "    model_settings['fingerprint_size']\n",
        "    if output_representation != 'raw' else model_settings['desired_samples'],\n",
        "    # noqa\n",
        "    num_classes=model_settings['label_count'],\n",
        "    **model_settings)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gery03Pa4mGF"
      },
      "source": [
        "# embed()\n",
        "checkpoints_path = os.path.join(checkpt_dir, 'conv_1d_time_stacked_model')\n",
        "if not os.path.exists(checkpoints_path):\n",
        "  os.makedirs(checkpoints_path)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j18v_aG_5b-m"
      },
      "source": [
        "callbacks = [\n",
        "      ConfusionMatrixCallback(\n",
        "          val_gen,\n",
        "          ap.set_size('validation') // batch_size,\n",
        "          wanted_words=prepare_words_list(get_classes(wanted_only=True)),\n",
        "          all_words=prepare_words_list(classes),\n",
        "          label2int=ap.word_to_index),\n",
        "      ReduceLROnPlateau(\n",
        "          monitor='val_categorical_accuracy',\n",
        "          mode='max',\n",
        "          factor=0.5,\n",
        "          patience=4,\n",
        "          verbose=1,\n",
        "          min_lr=1e-5),\n",
        "      TensorBoard(log_dir='logs'),\n",
        "      ModelCheckpoint(\n",
        "          os.path.join(checkpoints_path,\n",
        "                       'ep-{epoch:03d}-vl.hdf5'),\n",
        "          save_best_only=True,\n",
        "          monitor='val_loss',\n",
        "          mode='max')\n",
        "  ]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIgfrY0U5eVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a7dc74-1038-4f06-f03a-3a961ff1c601"
      },
      "source": [
        "model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=ap.set_size('training') // batch_size,\n",
        "    epochs=25,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "452/570 [======================>.......] - ETA: 15s - batch: 225.5000 - size: 64.0000 - loss: 0.7375 - categorical_accuracy: 0.7623\n",
            "[Ep:001: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.7127 - categorical_accuracy: 0.7705\n",
            "[Ep:001: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 84s 147ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.7127 - categorical_accuracy: 0.7705\n",
            "Epoch 2/25\n",
            "452/570 [======================>.......] - ETA: 15s - batch: 225.5000 - size: 64.0000 - loss: 0.5344 - categorical_accuracy: 0.8304\n",
            "[Ep:002: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.5182 - categorical_accuracy: 0.8364\n",
            "[Ep:002: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 84s 148ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.5182 - categorical_accuracy: 0.8364\n",
            "Epoch 3/25\n",
            "452/570 [======================>.......] - ETA: 15s - batch: 225.5000 - size: 64.0000 - loss: 0.4168 - categorical_accuracy: 0.8709\n",
            "[Ep:003: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.4131 - categorical_accuracy: 0.8724\n",
            "[Ep:003: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 83s 145ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.4131 - categorical_accuracy: 0.8724\n",
            "Epoch 4/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.3584 - categorical_accuracy: 0.8918\n",
            "[Ep:004: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.3561 - categorical_accuracy: 0.8930\n",
            "[Ep:004: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.3561 - categorical_accuracy: 0.8930\n",
            "Epoch 5/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.3171 - categorical_accuracy: 0.9052\n",
            "[Ep:005: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.3145 - categorical_accuracy: 0.9061\n",
            "[Ep:005: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.3145 - categorical_accuracy: 0.9061\n",
            "Epoch 6/25\n",
            "  3/570 [..............................] - ETA: 19s - batch: 1.0000 - size: 64.0000 - loss: 0.3256 - categorical_accuracy: 0.9167    "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "  return self._getitem_tuple(key)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.2893 - categorical_accuracy: 0.9144\n",
            "[Ep:006: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.2856 - categorical_accuracy: 0.9151\n",
            "[Ep:006: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.2856 - categorical_accuracy: 0.9151\n",
            "Epoch 7/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.2532 - categorical_accuracy: 0.9247\n",
            "[Ep:007: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.2535 - categorical_accuracy: 0.9244\n",
            "[Ep:007: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.2535 - categorical_accuracy: 0.9244\n",
            "Epoch 8/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.2432 - categorical_accuracy: 0.9286\n",
            "[Ep:008: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.2447 - categorical_accuracy: 0.9281\n",
            "[Ep:008: validation-mode]\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 142ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.2447 - categorical_accuracy: 0.9281\n",
            "Epoch 9/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1833 - categorical_accuracy: 0.9484\n",
            "[Ep:009: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1807 - categorical_accuracy: 0.9492\n",
            "[Ep:009: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1807 - categorical_accuracy: 0.9492\n",
            "Epoch 10/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1637 - categorical_accuracy: 0.9545\n",
            "[Ep:010: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1619 - categorical_accuracy: 0.9552\n",
            "[Ep:010: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1619 - categorical_accuracy: 0.9552\n",
            "Epoch 11/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1574 - categorical_accuracy: 0.9558\n",
            "[Ep:011: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1563 - categorical_accuracy: 0.9560\n",
            "[Ep:011: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1563 - categorical_accuracy: 0.9560\n",
            "Epoch 12/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1500 - categorical_accuracy: 0.9586\n",
            "[Ep:012: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1486 - categorical_accuracy: 0.9592\n",
            "[Ep:012: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1486 - categorical_accuracy: 0.9592\n",
            "Epoch 13/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1465 - categorical_accuracy: 0.9612\n",
            "[Ep:013: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1450 - categorical_accuracy: 0.9617\n",
            "[Ep:013: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1450 - categorical_accuracy: 0.9617\n",
            "Epoch 14/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1315 - categorical_accuracy: 0.9643\n",
            "[Ep:014: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1310 - categorical_accuracy: 0.9645\n",
            "[Ep:014: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1310 - categorical_accuracy: 0.9645\n",
            "Epoch 15/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1323 - categorical_accuracy: 0.9631\n",
            "[Ep:015: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1306 - categorical_accuracy: 0.9638\n",
            "[Ep:015: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1306 - categorical_accuracy: 0.9638\n",
            "Epoch 16/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1319 - categorical_accuracy: 0.9646\n",
            "[Ep:016: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1297 - categorical_accuracy: 0.9655\n",
            "[Ep:016: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1297 - categorical_accuracy: 0.9655\n",
            "Epoch 17/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1234 - categorical_accuracy: 0.9669\n",
            "[Ep:017: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1200 - categorical_accuracy: 0.9681\n",
            "[Ep:017: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1200 - categorical_accuracy: 0.9681\n",
            "Epoch 18/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1185 - categorical_accuracy: 0.9684\n",
            "[Ep:018: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1157 - categorical_accuracy: 0.9695\n",
            "[Ep:018: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1157 - categorical_accuracy: 0.9695\n",
            "Epoch 19/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1200 - categorical_accuracy: 0.9682\n",
            "[Ep:019: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1196 - categorical_accuracy: 0.9686\n",
            "[Ep:019: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1196 - categorical_accuracy: 0.9686\n",
            "Epoch 20/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1093 - categorical_accuracy: 0.9719\n",
            "[Ep:020: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1083 - categorical_accuracy: 0.9722\n",
            "[Ep:020: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1083 - categorical_accuracy: 0.9722\n",
            "Epoch 21/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.1083 - categorical_accuracy: 0.9715\n",
            "[Ep:021: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.1058 - categorical_accuracy: 0.9727\n",
            "[Ep:021: validation-mode]\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.1058 - categorical_accuracy: 0.9727\n",
            "Epoch 22/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.0872 - categorical_accuracy: 0.9797\n",
            "[Ep:022: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0879 - categorical_accuracy: 0.9791\n",
            "[Ep:022: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0879 - categorical_accuracy: 0.9791\n",
            "Epoch 23/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.0783 - categorical_accuracy: 0.9826\n",
            "[Ep:023: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0772 - categorical_accuracy: 0.9828\n",
            "[Ep:023: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0772 - categorical_accuracy: 0.9828\n",
            "Epoch 24/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.0783 - categorical_accuracy: 0.9821\n",
            "[Ep:024: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0770 - categorical_accuracy: 0.9825\n",
            "[Ep:024: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0770 - categorical_accuracy: 0.9825\n",
            "Epoch 25/25\n",
            "452/570 [======================>.......] - ETA: 14s - batch: 225.5000 - size: 64.0000 - loss: 0.0762 - categorical_accuracy: 0.9826\n",
            "[Ep:025: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0761 - categorical_accuracy: 0.9826\n",
            "[Ep:025: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 141ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0761 - categorical_accuracy: 0.9826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff4637e1898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "647RTSMPGtBz"
      },
      "source": [
        "model_dir = Path(base_dir,'speech_commands.hdf5')\n",
        "model.save(model_dir)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgm9dXX6WPoH"
      },
      "source": [
        "model.save('speech_commands.hdf5')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GKhQwcXH5yR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070c61aa-bf5b-4f54-f0d5-9bc028a646cf"
      },
      "source": [
        "eval_res = model.evaluate_generator(val_gen,\n",
        "                                      ap.set_size('validation') // batch_size)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:1273: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Ep:026: validation-mode]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWvxUQTAIIKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef94459b-2291-4d8b-80b8-ade1da4683ae"
      },
      "source": [
        "print(eval_res)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.2923269168190334, 0.92617756]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bau8_eBDkzpd"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\r\n",
        "from keras import backend as K\r\n",
        "from keras.utils import CustomObjectScope"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVPgbQpok4k6"
      },
      "source": [
        "def relu6(x):\r\n",
        "    return K.relu(x, max_value=6)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6cZmUK0k7aD",
        "outputId": "8886f08b-0f0a-4eb8-a1a8-8ba37354f1a2"
      },
      "source": [
        "with CustomObjectScope({'relu6': relu6}):\r\n",
        "    tflite_model = tf.lite.TFLiteConverter.from_keras_model_file(\r\n",
        "        'speech_commands.hdf5').convert()\r\n",
        "    with open('model.tflite', 'wb') as f:\r\n",
        "        f.write(tflite_model)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/util.py:327: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py:856: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpnd4l7t92/assets\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpnd4l7t92/variables/variables\n",
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n",
            "INFO:tensorflow:input tensors info: \n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input_1\n",
            "INFO:tensorflow: tensor name: serving_default_input_1:0, shape: (-1, 16000), type: DT_FLOAT\n",
            "INFO:tensorflow:output tensors info: \n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: reshape_1\n",
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 12), type: DT_FLOAT\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpnd4l7t92/variables/variables\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}