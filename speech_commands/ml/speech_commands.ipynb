{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech_commands.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrOnc95wvhhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMxdyA9uxLD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a7141675-531c-4781-acf1-f0b88b05d490"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=513b527eb8dcdb5cee401095826a16fcd4491549241ddb657c180acf9b075661\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBhqp0GwwcMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import wget\n",
        "import tarfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Yx_17Tweli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from shutil import rmtree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cecoFI2zwgg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_URL = 'http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz'\n",
        "ARCHIVE = os.path.basename(DATASET_URL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUqYsJWuwmHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "219b9ea1-391c-499f-ddab-c6657f982586"
      },
      "source": [
        "wget.download(DATASET_URL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'speech_commands_v0.01.tar.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FT2VH_qEe8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fb73c00e-b771-4841-f6b8-19f96ca00748"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'speech/'\n",
        "import sys\n",
        "sys.path.append(base_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt98m8hMEZL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "current_dir = Path.cwd()\n",
        "data_dir = Path(current_dir,'data')\n",
        "train_dir = Path(data_dir, 'train')\n",
        "if os.path.exists(train_dir):\n",
        "  rmtree(train_dir)\n",
        "os.makedirs(train_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54Cw8-8pwrsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tarfile.open(ARCHIVE, 'r:gz') as tar:\n",
        "  # tar.extractall(path='data/train')\n",
        "  tar.extractall(path=train_dir)\n",
        "\n",
        "os.remove(ARCHIVE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATk4Ruk1Q8xK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6c145d17-8c6b-47d8-c78a-0e359d14ce12"
      },
      "source": [
        "from pathlib import Path\n",
        "current_dir = Path.cwd()\n",
        "data_dir = Path(current_dir,'data')\n",
        "train_dir = Path(data_dir, 'train')\n",
        "checkpt_dir = Path(current_dir,'checkpoint')\n",
        "print(\"train_dir = \",train_dir)\n",
        "print(\"checkpt_dir = \",checkpt_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_dir =  /content/data/train\n",
            "checkpt_dir =  /content/checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kREgOmy-PCAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "132d5418-86e7-411e-f679-5fe1f62e492b"
      },
      "source": [
        "!pip install keras-applications==1.0.7\n",
        "!pip install keras_preprocessing==1.0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-applications==1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 30.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications==1.0.7) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications==1.0.7) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications==1.0.7) (1.15.0)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.7\n",
            "Collecting keras_preprocessing==1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: keras>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing==1.0.1) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing==1.0.1) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing==1.0.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing==1.0.1) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras_preprocessing==1.0.1) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras_preprocessing==1.0.1) (2.10.0)\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement keras-preprocessing<1.2,>=1.1.1, but you'll have keras-preprocessing 1.0.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-preprocessing\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "Successfully installed keras-preprocessing-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L66K_IbURbBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "5fbd9950-cff7-4389-fd2c-31290fd10cf9"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Collecting keras-preprocessing<1.2,>=1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42kB)\n",
            "\r\u001b[K     |███████▊                        | 10kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 20kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 30kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.31.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (49.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Installing collected packages: keras-preprocessing\n",
            "  Found existing installation: Keras-Preprocessing 1.0.1\n",
            "    Uninstalling Keras-Preprocessing-1.0.1:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.1\n",
            "Successfully installed keras-preprocessing-1.1.2\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTfbZiKWUPSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "86d3e5e9-2d6b-4a33-dfc6-71837924a7ab"
      },
      "source": [
        "!pip install git+https://github.com/hyperopt/hyperopt-sklearn.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
            "  Cloning https://github.com/hyperopt/hyperopt-sklearn.git to /tmp/pip-req-build-ls7ly9mr\n",
            "  Running command git clone -q https://github.com/hyperopt/hyperopt-sklearn.git /tmp/pip-req-build-ls7ly9mr\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (0.1.2)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (1.15.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (3.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (4.41.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->hpsklearn==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hpsklearn==0.0.3) (4.4.2)\n",
            "Building wheels for collected packages: hpsklearn\n",
            "  Building wheel for hpsklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpsklearn: filename=hpsklearn-0.0.3-cp36-none-any.whl size=26798 sha256=2a6e2362a8c42d92b91d0a83ca675db32caa8715ca8dd50b4e86a0c5beb65db7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bpnkezg8/wheels/28/93/20/67dca95c2aaa13466b4900ba79a7bab66022e50ce44f8a438d\n",
            "Successfully built hpsklearn\n",
            "Installing collected packages: nose, hpsklearn\n",
            "Successfully installed hpsklearn-0.0.3 nose-1.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umwPXBHVcw0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "b6f0c01d-4e66-4a01-dd52-1fb674b60b21"
      },
      "source": [
        "! pip install scikit-learn==0.21\n",
        "! pip install pandas==0.24.2\n",
        "! pip install pandas_ml==0.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==0.21 in /usr/local/lib/python3.6/dist-packages (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21) (1.4.1)\n",
            "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas==0.24.2) (1.15.0)\n",
            "Collecting pandas_ml\n",
            "  Using cached https://files.pythonhosted.org/packages/ae/72/6d90debfcb9ea74ec00927fa7ed0204dcc560b1f9ffcd8b239daa7fd106d/pandas_ml-0.6.1-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from pandas_ml) (0.24.2)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python3.6/dist-packages (from pandas_ml) (1.1.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->pandas_ml) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->pandas_ml) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->pandas_ml) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.0->pandas_ml) (1.15.0)\n",
            "Installing collected packages: pandas-ml\n",
            "Successfully installed pandas-ml-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R3tXGJnAXBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f172a2f4-0d58-40bd-9ed2-7ab77fd94148"
      },
      "source": [
        "! pip uninstall -y pandas_ml\n",
        "! pip install pandas_ml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling pandas-ml-0.5.0:\n",
            "  Successfully uninstalled pandas-ml-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a76jDvt9u0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import model\n",
        "import generator\n",
        "import classes\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0g4YdWMx6h4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e872e7fc-71a6-45ab-c253-6e89f9d6649e"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.callbacks import TensorBoard\n",
        "from callbacks import ConfusionMatrixCallback\n",
        "from model import speech_model, prepare_model_settings\n",
        "from generator import AudioProcessor, prepare_words_list\n",
        "from classes import get_classes\n",
        "from utils import data_gen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9BFBlIwrg29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8e1570c2-a683-48b2-b190-2d3173e3887f"
      },
      "source": [
        "# args = parser.parse_args()\n",
        "args = {}\n",
        "args['data_dirs'] = train_dir\n",
        "args['sample_rate'] = 16000\n",
        "args['batch_size'] = 64\n",
        "args['output_representation'] = 'raw'\n",
        "# parser.print_help()\n",
        "print('input args: ', args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input args:  {'data_dirs': PosixPath('/content/data/train'), 'sample_rate': 16000, 'batch_size': 64, 'output_representation': 'raw'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riwyHrUu6u-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "9e0f6f2a-1a76-41fe-adaf-06ceebf1054f"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/11/763f55d3d15efd778ef24453f126e6c33635680e5a2bb346da3fab5997cb/tensorflow_gpu-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.31.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (49.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWWQ23G2-m9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.compat.v1.keras import backend as K\n",
        "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.0)\n",
        "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "K.set_session(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQHaFkEH56z6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "65cf754c-85ac-4fd9-f98e-5159081bf0af"
      },
      "source": [
        "\n",
        "p = args['data_dirs']\n",
        "print(\"p = \", p)\n",
        "data_dirs = [str(x) for x in p.iterdir() if x.is_dir()]\n",
        "# data_dirs=(args['data_dirs'])\n",
        "print(\"data_dirs = \", data_dirs)\n",
        "output_representation = args['output_representation']\n",
        "sample_rate = args['sample_rate']\n",
        "batch_size = args['batch_size']\n",
        "classes = get_classes(wanted_only=True)\n",
        "print(\"classes = \", classes)\n",
        "model_settings = prepare_model_settings(\n",
        "    label_count=len(prepare_words_list(classes)),\n",
        "    sample_rate=sample_rate,\n",
        "    clip_duration_ms=1000,\n",
        "    window_size_ms=30.0,\n",
        "    window_stride_ms=10.0,\n",
        "    dct_coefficient_count=80,\n",
        "    num_log_mel_features=60,\n",
        "    output_representation=output_representation)\n",
        "\n",
        "print(model_settings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p =  /content/data/train\n",
            "data_dirs =  ['/content/data/train/cat', '/content/data/train/no', '/content/data/train/house', '/content/data/train/one', '/content/data/train/two', '/content/data/train/off', '/content/data/train/three', '/content/data/train/up', '/content/data/train/seven', '/content/data/train/stop', '/content/data/train/left', '/content/data/train/happy', '/content/data/train/go', '/content/data/train/down', '/content/data/train/marvin', '/content/data/train/bird', '/content/data/train/wow', '/content/data/train/nine', '/content/data/train/bed', '/content/data/train/zero', '/content/data/train/five', '/content/data/train/right', '/content/data/train/_background_noise_', '/content/data/train/six', '/content/data/train/yes', '/content/data/train/sheila', '/content/data/train/eight', '/content/data/train/dog', '/content/data/train/on', '/content/data/train/four', '/content/data/train/tree']\n",
            "classes =  ['stop', 'down', 'off', 'right', 'up', 'go', 'on', 'yes', 'left', 'no']\n",
            "{'desired_samples': 16000, 'window_size_samples': 480, 'window_stride_samples': 160, 'spectrogram_length': 98, 'spectrogram_frequencies': 257, 'dct_coefficient_count': 80, 'fingerprint_size': 16000, 'label_count': 12, 'sample_rate': 16000, 'num_log_mel_features': 60}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8vsMUb1_lm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e8cbe316-1611-4b6e-87e7-b5fb187e2394"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "ap = AudioProcessor(\n",
        "    data_dirs=data_dirs,\n",
        "    wanted_words=classes,\n",
        "    silence_percentage=13.0,\n",
        "    unknown_percentage=60.0,\n",
        "    validation_percentage=10.0,\n",
        "    testing_percentage=0.0,\n",
        "    model_settings=model_settings,\n",
        "    output_representation=output_representation)\n",
        "train_gen = data_gen(ap, sess, batch_size=batch_size, mode='training')\n",
        "val_gen = data_gen(ap, sess, batch_size=batch_size, mode='validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "shape of self.spectrogram_ =  Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
            "prepare_processing_graph completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONXA3qS53U80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = speech_model(\n",
        "    'conv_1d_time_stacked',\n",
        "    model_settings['fingerprint_size']\n",
        "    if output_representation != 'raw' else model_settings['desired_samples'],\n",
        "    # noqa\n",
        "    num_classes=model_settings['label_count'],\n",
        "    **model_settings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gery03Pa4mGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed()\n",
        "checkpoints_path = os.path.join(checkpt_dir, 'conv_1d_time_stacked_model')\n",
        "if not os.path.exists(checkpoints_path):\n",
        "  os.makedirs(checkpoints_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j18v_aG_5b-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "      ConfusionMatrixCallback(\n",
        "          val_gen,\n",
        "          ap.set_size('validation') // batch_size,\n",
        "          wanted_words=prepare_words_list(get_classes(wanted_only=True)),\n",
        "          all_words=prepare_words_list(classes),\n",
        "          label2int=ap.word_to_index),\n",
        "      ReduceLROnPlateau(\n",
        "          monitor='val_categorical_accuracy',\n",
        "          mode='max',\n",
        "          factor=0.5,\n",
        "          patience=4,\n",
        "          verbose=1,\n",
        "          min_lr=1e-5),\n",
        "      TensorBoard(log_dir='logs'),\n",
        "      ModelCheckpoint(\n",
        "          os.path.join(checkpoints_path,\n",
        "                       'ep-{epoch:03d}-vl.hdf5'),\n",
        "          save_best_only=True,\n",
        "          monitor='val_loss',\n",
        "          mode='max')\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIgfrY0U5eVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d942210c-9bd7-477a-9537-d4e8eea971ab"
      },
      "source": [
        "model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=ap.set_size('training') // batch_size,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0394 - categorical_accuracy: 0.9946\n",
            "[Ep:062: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0398 - categorical_accuracy: 0.9945\n",
            "[Ep:064: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 144ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0398 - categorical_accuracy: 0.9945\n",
            "Epoch 2/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0391 - categorical_accuracy: 0.9951\n",
            "[Ep:063: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0390 - categorical_accuracy: 0.9951\n",
            "[Ep:065: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 142ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0390 - categorical_accuracy: 0.9951\n",
            "Epoch 3/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0411 - categorical_accuracy: 0.9940\n",
            "[Ep:064: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0412 - categorical_accuracy: 0.9939\n",
            "[Ep:066: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 142ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0412 - categorical_accuracy: 0.9939\n",
            "Epoch 4/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0387 - categorical_accuracy: 0.9952\n",
            "[Ep:065: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0388 - categorical_accuracy: 0.9951\n",
            "[Ep:067: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 143ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0388 - categorical_accuracy: 0.9951\n",
            "Epoch 5/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0402 - categorical_accuracy: 0.9948\n",
            "[Ep:066: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0400 - categorical_accuracy: 0.9948\n",
            "[Ep:068: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 144ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0400 - categorical_accuracy: 0.9948\n",
            "Epoch 6/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0400 - categorical_accuracy: 0.9949\n",
            "[Ep:067: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0401 - categorical_accuracy: 0.9948\n",
            "[Ep:069: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 144ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0401 - categorical_accuracy: 0.9948\n",
            "Epoch 7/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0395 - categorical_accuracy: 0.9947\n",
            "[Ep:068: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0397 - categorical_accuracy: 0.9945\n",
            "[Ep:070: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 143ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0397 - categorical_accuracy: 0.9945\n",
            "Epoch 8/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0391 - categorical_accuracy: 0.9945\n",
            "[Ep:069: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0389 - categorical_accuracy: 0.9945\n",
            "[Ep:071: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 143ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0389 - categorical_accuracy: 0.9945\n",
            "Epoch 9/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0375 - categorical_accuracy: 0.9956\n",
            "[Ep:070: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0378 - categorical_accuracy: 0.9956\n",
            "[Ep:072: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 144ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0378 - categorical_accuracy: 0.9956\n",
            "Epoch 10/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0387 - categorical_accuracy: 0.9949\n",
            "[Ep:071: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0383 - categorical_accuracy: 0.9950\n",
            "[Ep:073: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 142ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0383 - categorical_accuracy: 0.9950\n",
            "Epoch 11/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0374 - categorical_accuracy: 0.9954\n",
            "[Ep:072: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0375 - categorical_accuracy: 0.9954\n",
            "[Ep:074: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 142ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0375 - categorical_accuracy: 0.9954\n",
            "Epoch 12/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0395 - categorical_accuracy: 0.9949\n",
            "[Ep:073: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0390 - categorical_accuracy: 0.9950\n",
            "[Ep:075: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 142ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0390 - categorical_accuracy: 0.9950\n",
            "Epoch 13/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0379 - categorical_accuracy: 0.9951\n",
            "[Ep:074: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0378 - categorical_accuracy: 0.9952\n",
            "[Ep:076: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 144ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0378 - categorical_accuracy: 0.9952\n",
            "Epoch 14/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0385 - categorical_accuracy: 0.9951\n",
            "[Ep:075: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0386 - categorical_accuracy: 0.9952\n",
            "[Ep:077: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 81s 143ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0386 - categorical_accuracy: 0.9952\n",
            "Epoch 15/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0380 - categorical_accuracy: 0.9951\n",
            "[Ep:076: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0379 - categorical_accuracy: 0.9952\n",
            "[Ep:078: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 144ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0379 - categorical_accuracy: 0.9952\n",
            "Epoch 16/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0374 - categorical_accuracy: 0.9954\n",
            "[Ep:077: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0374 - categorical_accuracy: 0.9953\n",
            "[Ep:079: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 144ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0374 - categorical_accuracy: 0.9953\n",
            "Epoch 17/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0386 - categorical_accuracy: 0.9948\n",
            "[Ep:078: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0391 - categorical_accuracy: 0.9946\n",
            "[Ep:080: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 144ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0391 - categorical_accuracy: 0.9946\n",
            "Epoch 18/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0374 - categorical_accuracy: 0.9959\n",
            "[Ep:079: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0378 - categorical_accuracy: 0.9957\n",
            "[Ep:081: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0378 - categorical_accuracy: 0.9957\n",
            "Epoch 19/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0377 - categorical_accuracy: 0.9952\n",
            "[Ep:080: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0381 - categorical_accuracy: 0.9950\n",
            "[Ep:082: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 80s 140ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0381 - categorical_accuracy: 0.9950\n",
            "Epoch 20/50\n",
            "525/570 [==========================>...] - ETA: 5s - batch: 262.0000 - size: 64.0000 - loss: 0.0368 - categorical_accuracy: 0.9960\n",
            "[Ep:081: training-mode]\n",
            "570/570 [==============================] - ETA: 0s - batch: 284.5000 - size: 64.0000 - loss: 0.0366 - categorical_accuracy: 0.9960\n",
            "[Ep:083: validation-mode]\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "570/570 [==============================] - 82s 144ms/step - batch: 284.5000 - size: 64.0000 - loss: 0.0366 - categorical_accuracy: 0.9960\n",
            "Epoch 21/50\n",
            "326/570 [================>.............] - ETA: 30s - batch: 162.5000 - size: 64.0000 - loss: 0.0365 - categorical_accuracy: 0.9959"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "647RTSMPGtBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = Path(base_dir,'speech_commands.hdf5')\n",
        "model.save(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GKhQwcXH5yR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e997db56-ebb3-4582-fec6-1ad3f4bbec14"
      },
      "source": [
        "eval_res = model.evaluate_generator(val_gen,\n",
        "                                      ap.set_size('validation') // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Ep:063: validation-mode]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWvxUQTAIIKB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dc31125-e9a5-4241-dd78-74806e3c7a0f"
      },
      "source": [
        "print(eval_res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.2604759057470854, 0.9413496]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}